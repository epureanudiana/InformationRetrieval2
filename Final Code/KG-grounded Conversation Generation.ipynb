{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KG-grounded Conversation Generation.ipynb","provenance":[],"collapsed_sections":["WzzwoEPKlxR9","mKRmPKiuCsJw","Mm_kKs6mC7aB","rBE_2AZCC-1e"],"toc_visible":true,"authorship_tag":"ABX9TyNYEXuRFeZihTFUFE9etckg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"53911d72e0fa477c877f68de3e288339":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c83335ab6934c339b61f943ff9dc05e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a10b5c8f60cf4c9fb6b9d4935879d6b0","IPY_MODEL_cda385fdc6f047f580d9c0fabe68155d"]}},"6c83335ab6934c339b61f943ff9dc05e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a10b5c8f60cf4c9fb6b9d4935879d6b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0daa32cdc0a8468ea1ed8f0ec4ffec11","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":642,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":642,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41cb63ff363e46aa93c95c96dff7514e"}},"cda385fdc6f047f580d9c0fabe68155d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb72ea6c9b2e49d09da9719e7f1f201b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 642/642 [00:01&lt;00:00, 515B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f45013a6d2a9450fb2d77bd8ce626d0e"}},"0daa32cdc0a8468ea1ed8f0ec4ffec11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41cb63ff363e46aa93c95c96dff7514e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb72ea6c9b2e49d09da9719e7f1f201b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f45013a6d2a9450fb2d77bd8ce626d0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"105ded7338954c36b3ecd845c245c2fa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2482088589b5413e9ae8bf90cfa4649a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_acf4eadbc9694062aa63701dd7092e8a","IPY_MODEL_b72dec3dd5eb4bebb830986f12d26163"]}},"2482088589b5413e9ae8bf90cfa4649a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acf4eadbc9694062aa63701dd7092e8a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d2e420a58483450fbbe213dcfb49fcf7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1042301,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1042301,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_297ae016bb2d437abf78a9f6735e3b2a"}},"b72dec3dd5eb4bebb830986f12d26163":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_295b10baa8fa4629bf222c7bdbafba53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.04M/1.04M [00:03&lt;00:00, 311kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c4a21674971544b8bb1b1dbb3a35d328"}},"d2e420a58483450fbbe213dcfb49fcf7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"297ae016bb2d437abf78a9f6735e3b2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"295b10baa8fa4629bf222c7bdbafba53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c4a21674971544b8bb1b1dbb3a35d328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dab46530f6749218f7eb8dd916c1190":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_189804e9b11c41a99d4584b935de759c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97b416efe9334044b5a9a2ef18591ea8","IPY_MODEL_be62fdc8776d493bac7cea4fbb0c4aa5"]}},"189804e9b11c41a99d4584b935de759c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97b416efe9334044b5a9a2ef18591ea8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9bbc015a08d3407e8efeb4d55514d0fb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b743d9fd8faf47bab809e2b04cb8f1f1"}},"be62fdc8776d493bac7cea4fbb0c4aa5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d1f2ec87be1411c8d09d4a4e7863a80","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:01&lt;00:00, 232kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06633637d89e43598bf06e3cf2daf1fa"}},"9bbc015a08d3407e8efeb4d55514d0fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b743d9fd8faf47bab809e2b04cb8f1f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d1f2ec87be1411c8d09d4a4e7863a80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06633637d89e43598bf06e3cf2daf1fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4307ee8b1dc4da48c87eb89a7de9c2a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0fce6d5fbb0e407dae5fd60397ff1512","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_916de07769624e8485d31adc9719ce69","IPY_MODEL_cadf18220b92433ba52e85d6568080a9"]}},"0fce6d5fbb0e407dae5fd60397ff1512":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"916de07769624e8485d31adc9719ce69":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9e0c0b744f4e4b429edca3be16b134f0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":862955157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":862955157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_34bfdd5d53314d7b84cfa0e10f7f2961"}},"cadf18220b92433ba52e85d6568080a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1cebcf9cf1af4e949d1fd68a472463af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 863M/863M [01:28&lt;00:00, 9.78MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c6951f607e44e1cb6a2d098816b5453"}},"9e0c0b744f4e4b429edca3be16b134f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"34bfdd5d53314d7b84cfa0e10f7f2961":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cebcf9cf1af4e949d1fd68a472463af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c6951f607e44e1cb6a2d098816b5453":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1b58ea3b210d4a25ad662c6a5596433e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7b80dbf2c78c496aa47ef69b889fe4ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4e129a8caa8e4207b8a63471ffefb648","IPY_MODEL_e4ffd186bb134ea6a084df71ebd75862"]}},"7b80dbf2c78c496aa47ef69b889fe4ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4e129a8caa8e4207b8a63471ffefb648":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c428b04d9f4b4f259cfa7f286326372f","_dom_classes":[],"description":"Epoch:   0%","_model_name":"FloatProgressModel","bar_style":"danger","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f811eb77e254d3ab359fd027f05f104"}},"e4ffd186bb134ea6a084df71ebd75862":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bcdc84746df24acbb9f2bc80123458e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/3 [05:38&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c47657371fff4ad3966b31777ed04516"}},"c428b04d9f4b4f259cfa7f286326372f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f811eb77e254d3ab359fd027f05f104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcdc84746df24acbb9f2bc80123458e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c47657371fff4ad3966b31777ed04516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"784565a1ba054a87ac3f3fbfb4f8d61f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_490e217f758e427781158e7ebd12264b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0dfcdbad69dd428e94abf492d690955c","IPY_MODEL_c69474a30a7e4f13b148694a2a7785a8"]}},"490e217f758e427781158e7ebd12264b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0dfcdbad69dd428e94abf492d690955c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1017ac86f464483a8e0f6c5797cd91f9","_dom_classes":[],"description":"Iteration:  29%","_model_name":"FloatProgressModel","bar_style":"danger","max":6612,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1903,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f5339846004d46d98e6186563658d9f5"}},"c69474a30a7e4f13b148694a2a7785a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5facdd353e248f2a15b1bca7a1626e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1903/6612 [05:38&lt;13:41,  5.73it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c02cdd08d62543d3b713eb04025b9d4b"}},"1017ac86f464483a8e0f6c5797cd91f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f5339846004d46d98e6186563658d9f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5facdd353e248f2a15b1bca7a1626e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c02cdd08d62543d3b713eb04025b9d4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"FiSdECa6k30z"},"source":["# KG-Grounded Conversation Generation"]},{"cell_type":"markdown","metadata":{"id":"fzL5D2oGN-c-"},"source":["Authors: *Maria Diea*, *Diana Epureanu*, and *Teodora Stoenescu* <br>\n","Supervisor: *Svitlana Vakulenko*"]},{"cell_type":"markdown","metadata":{"id":"uZUPLYYulV5c"},"source":["Before running the notebook make you sure have the <tt> opendialkg.csv</tt> and <tt>opendialkg_triples.txt</tt> files in the same folder as your notebook. The files can be downloaded from https://github.com/facebookresearch/opendialkg/tree/master/data. <br>\n","\n","Read the OpenDialKG Corpus where each dialog turn is paired with KG paths that connect its previous turn. The dataset is formatted as a csv file, where columns are: *Messages, User Rating, Assistant Rating*. <br>\n","Each row refers to a dialog session, which is a JSON-formatted *list* of each action. <br>\n","More details: https://github.com/facebookresearch/opendialkg"]},{"cell_type":"markdown","metadata":{"id":"-NS9WySsH3CZ"},"source":["Make sure you have the following files:\n","- ```opendialkg.csv```\n","- ```opendialkg_triples.txt```\n","- ```kanye_west.csv```\n","- ```got.csv```\n","- ```shrek.csv```\n","-```ranker_input_pruned.pkl```\n","\n","The following files are optional but can be used to avoid re-training the models:\n","- ```BiOpenDialKG.csv``` (pre-process dataset)\n","- ```best_model_state.bin``` (pre-trained classifier)\n","- ```output-finetuned``` (finetuned DialoGPT)\n"]},{"cell_type":"markdown","metadata":{"id":"aSxP3xZOD3am"},"source":["Set up your working directory if needed."]},{"cell_type":"code","metadata":{"id":"PKFzxfO9nXdM","executionInfo":{"status":"ok","timestamp":1603470390586,"user_tz":-180,"elapsed":2165,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"00e584e2-cdb1-444e-af5f-c56a9c093c23","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YQzHYheoncAf","executionInfo":{"status":"ok","timestamp":1603470391586,"user_tz":-180,"elapsed":1228,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks\")"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rvrPBWdeD8Lm"},"source":["Import libraries, initiliaze devices and datasets. "]},{"cell_type":"code","metadata":{"id":"KPHWAjIkmN2N","executionInfo":{"status":"ok","timestamp":1603470397366,"user_tz":-180,"elapsed":5451,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"febdfcc3-51ef-4d30-da3c-614959747730","colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ppDYZVflPHJ","executionInfo":{"status":"ok","timestamp":1603470425603,"user_tz":-180,"elapsed":13091,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["import numpy as np\n","import pandas as pd\n","from pylab import rcParams\n","from toolz import interleave\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import json\n","import ast\n","import re\n","\n","import transformers\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelForSequenceClassification,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    BertModel, \n","    BertTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n","from collections import defaultdict\n","from textwrap import wrap\n","\n","from torch import nn, optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","\n","RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"pH_b_9N_p3Bf","executionInfo":{"status":"ok","timestamp":1603470427769,"user_tz":-180,"elapsed":2155,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["df = pd.read_csv('opendialkg.csv')\n","\n","# prune the dataset such that we only have the highest rated dialogues\n","top_rating = df['User Rating'][0]  # hard coded - the first entry has maximum scores\n","df = df[df['User Rating'] == top_rating]\n","df = df[df['Assistant Rating'] == top_rating]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f6woeGAvDs6E","executionInfo":{"status":"ok","timestamp":1603470430080,"user_tz":-180,"elapsed":4450,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["triples_df = pd.read_csv(\"opendialkg_triples.txt\", \n","                         sep='\\t', \n","                         names=['Subject', 'Relation', 'Object'])\n","triples_df.dropna(inplace=True)\n","triples_df['Relation'] = triples_df['Relation'].apply(lambda x: x[1:] if '~' in x else x)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"MT4OFnLHq-hx","executionInfo":{"status":"ok","timestamp":1603470431941,"user_tz":-180,"elapsed":1821,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"d72230e9-2521-4042-ba37-46bb8c1eb92b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["triples_df.dropna(inplace=True)\n","all_entities = set(triples_df['Subject'].values.tolist() + triples_df['Object'].values.tolist())\n","print('There are {0} entities in the knowledge graph.'.format(len(all_entities)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["There are 100716 entities in the knowledge graph.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x3vfuxYSqOIw"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"0C4gonqyla4T"},"source":["Set ```LOAD_PRE_DATASET```, ```LOAD_CLASSIFIER```, or ```LOAD_FINETUNED``` to True if you would like to use the already pre-processed data, the pre-trained classifier, or the already finetuned DialoGPT.\n","\n","Set ```DIALOGPT_FINETUNED``` to True if you are not using the already finetuned DialoGPT but you would like to finetune it here."]},{"cell_type":"code","metadata":{"id":"G6CaET4MohZG","executionInfo":{"status":"ok","timestamp":1603470433036,"user_tz":-180,"elapsed":2486,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["LOAD_PRE_DATASET = True\n","LOAD_CLASSIFIER = False\n","LOAD_FINETUNED = True\n","\n","ONLY_POSITIVE_TEST = False  # use only positive test instance for classifier test\n","PAIRED_DATA = False  # pair up data such that for every positive instance there is a negative one\n","PRE_PROCESSED_DATA = 'BiOpenDialKG.csv'  \n","CLASSIFIER_MODEL = 'best_model_state.bin'\n","FINETUNED_MODEL = 'output-finetuned'\n","DIALOGPT_CARD = 'microsoft/DialoGPT-medium'\n","DIALORPT_CARD = 'microsoft/DialogRPT-depth'\n","\n","# load bert model and tokenizer\n","PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n","tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZY0y3FF39nH2","executionInfo":{"status":"ok","timestamp":1603470436644,"user_tz":-180,"elapsed":2019,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["class BinaryClassifier(nn.Module):\n","  def __init__(self, n_classes):\n","    super(BinaryClassifier, self).__init__()\n","    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n","    self.drop = nn.Dropout(p=0.2)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes, bias=False)\n","  \n","  def forward(self, input_ids, attention_mask):\n","    _, pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","    output = self.drop(pooled_output)\n","    \n","    return torch.sigmoid(self.out(output))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFyEZzHEnqEs","executionInfo":{"status":"ok","timestamp":1603470576762,"user_tz":-180,"elapsed":138775,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"0b06cacb-6c97-4329-9947-1b42d24511f9","colab":{"base_uri":"https://localhost:8080/","height":171}},"source":["classifier = BinaryClassifier(2)\n","classifier = classifier.to(device)\n","EPOCHS = 1\n","  \n","if LOAD_PRE_DATASET:\n","  # load the pre-procssed dataset\n","  train_df = pd.read_csv(PRE_PROCESSED_DATA)\n","  train_df.drop(['Unnamed: 0'], axis=1, inplace=True)\n","\n","  # show more of the text message\n","  pd.set_option('display.max_colwidth', None)\n","\n","  # remove nans, if any\n","  train_df = train_df.dropna()\n","  print(train_df.isnull().sum())\n","\n","  if PAIRED_DATA:\n","    col_names = list(train_df.columns)\n","    data_positive = train_df[train_df[\"Label\"] == 1]\n","    data_negative = train_df[train_df[\"Label\"] == 0]\n","    train_df = pd.DataFrame(interleave([data_positive.values, data_negative.values]))\n","    train_df.columns = col_names\n","\n","if LOAD_CLASSIFIER:\n","  classifier.load_state_dict(torch.load(CLASSIFIER_MODEL, map_location=device))\n","\n","if LOAD_FINETUNED:\n","  generator_model = AutoModelWithLMHead.from_pretrained(FINETUNED_MODEL)\n","  generator_tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)\n","else:\n","  generator_model = AutoModelWithLMHead.from_pretrained(DIALOGPT_CARD)\n","  generator_tokenizer = AutoTokenizer.from_pretrained(DIALOGPT_CARD)\n","\n","ranker_tokenizer = AutoTokenizer.from_pretrained(DIALORPT_CARD)\n","ranker_model = AutoModelForSequenceClassification.from_pretrained(DIALORPT_CARD)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Message     0\n","Subject     0\n","Relation    0\n","Object      0\n","Label       0\n","dtype: int64\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wSSyJ5Jlk-up"},"source":["### Data Preparation\n","Either run these cells or load the already pre-processed dataset above. \n","\n","!! Choose between random or distribution based negative sampling."]},{"cell_type":"markdown","metadata":{"id":"WzzwoEPKlxR9"},"source":["#### Positive Sampling\n","\n","To sample positive entities, we look at the messages provided in the OpenDialKG and extract the entities present in the dialogue."]},{"cell_type":"code","metadata":{"id":"JwlAD-0dlj1w","executionInfo":{"status":"ok","timestamp":1603467439040,"user_tz":-180,"elapsed":28359,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["train_df = pd.DataFrame(columns=['Message', 'Subject', 'Relation', 'Object', 'Label'])\n","opendialkg = dict()  # data structure to hold the dialog history; indexed by integers\n","\n","for d, dialogue in enumerate(df['Messages']):\n","    opendialkg[d], r = [], 0  # dialogue d history and reply number\n","    dialogue = ast.literal_eval(dialogue)  # format string to list\n","    \n","    for response in dialogue:\n","        response = dict(response)\n","        \n","        # each reply in a dialogue is either a message or metadata\n","        if 'message' in response:\n","            opendialkg[d].append(response['message']) # record reply\n","            r += 1\n","            \n","        if 'metadata' in response:\n","            # make sure the kg path is available\n","            if 'path' in response['metadata']:\n","                if r == 0:\n","                    # metadata is the first dialogue line, out of the ordinary\n","                    continue\n","                \n","                # usually metadata directly follows the message\n","                message = opendialkg[d][r-1]\n","                \n","                for sbj, rel, obj in response['metadata']['path'][1]:\n","                    # for consistency: select only entities which are directly reffered in the previous message\n","                    if sbj in message:\n","                        if '~' in rel:\n","                            rel = rel[1:]  # relations randomly have a '~' symbol\n","                        train_df = train_df.append({'Message': message, \n","                                                    'Subject': sbj, \n","                                                     'Relation': rel, \n","                                                     'Object': obj, \n","                                                     'Label': 1}, ignore_index=True)\n","                        \n","                        opendialkg[d][r-1] = (opendialkg[d][r-1], (sbj, rel, obj))"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mKRmPKiuCsJw"},"source":["#### Negative Sampling\n"]},{"cell_type":"markdown","metadata":{"id":"Mm_kKs6mC7aB"},"source":["###### Distribution-based"]},{"cell_type":"markdown","metadata":{"id":"YJhYut2FA8ax"},"source":["Get distribution of relations for every entity."]},{"cell_type":"code","metadata":{"id":"7WpHnldfA8Bl","executionInfo":{"status":"ok","timestamp":1603467114606,"user_tz":-180,"elapsed":6918,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"f5f49c9d-e011-4ffe-9e62-f3d8caf81d07","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from tqdm import tqdm\n","\n","# create set of entities \n","entities = list(train_df[\"Subject\"].unique())\n"," \n","entityToPredicateDict = dict()\n","# creates dict with the following shape:\n","\"\"\"\"\n"," {entity_1: {relation1 : #occurences, ..., relation_n : #occurences}\n"," ...\n"," entity_n : {relation1 : #occurences, ..., relation_n : #occurences}\n"," }\n","\"\"\"\n","for entity in tqdm(entities):\n","    \n","    df_entity = train_df[train_df[\"Subject\"] == entity]\n","    \n","    predDistPerEntity = defaultdict(int)\n","    \n","    for index, row in df_entity.iterrows():\n","        \n","        relation = row[\"Relation\"]\n","        \n","        predDistPerEntity[relation] = predDistPerEntity[relation] + 1\n","        \n","    entityToPredicateDict[entity] = predDistPerEntity    "],"execution_count":15,"outputs":[{"output_type":"stream","text":["100%|██████████| 3539/3539 [00:03<00:00, 907.23it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Cd3HRfTJBNcl"},"source":["Get global distribution of relations."]},{"cell_type":"code","metadata":{"id":"BcIOa2SPBQMF","executionInfo":{"status":"ok","timestamp":1603467130398,"user_tz":-180,"elapsed":12508,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# create set of relations \n","relations = list(train_df[\"Relation\"].unique())\n"," \n","globalRelationDict = defaultdict(int)\n","\n","# creates dict with the following shape (based on entityToPredicateDict):\n","\"\"\"\"\n"," {relation_1: #occurences\n"," ...\n"," relation_n : #occurences\n"," }\n","\"\"\"\n","for entity in entityToPredicateDict:\n","    \n","    predDist = entityToPredicateDict[entity]\n","    \n","    for relation, count in predDist.items():\n","        \n","        globalRelationDict[relation] = globalRelationDict[relation] + count"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n3YkwbYgBSv4"},"source":["Get distribution of objects for each subject"]},{"cell_type":"code","metadata":{"id":"DNbEyzSqCPW9","executionInfo":{"status":"ok","timestamp":1603467141233,"user_tz":-180,"elapsed":7208,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"e79af4dd-7f56-409a-9793-45eb64a6adfc","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# create set of relations\n","subjects = list(train_df[\"Subject\"].unique())\n","\n","# create set of objects\n","objects = list(train_df[\"Object\"].unique())\n","\n","subjectToObjectDict = dict()\n","\n","#creates dict with the following shape\n","\n","\"\"\"\n","{subject_1: {object1 : #occurences, ..., object_n : #occurences}\n"," ...\n"," subject_n : {object1 : #occurences, ..., object_n : #occurences}\n"," }\n","\n","\"\"\"\n","\n","for subject in tqdm(subjects):\n","    \n","    df_subject = train_df[train_df[\"Subject\"] == subject]\n","    \n","    objectDistPerSubject = defaultdict(int)\n","    \n","    for index, row in df_subject.iterrows():\n","        \n","        object_ = row[\"Object\"]\n","        \n","        objectDistPerSubject[object_] = objectDistPerSubject[object_] + 1\n","        \n","    subjectToObjectDict[subject] = objectDistPerSubject"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 3539/3539 [00:03<00:00, 921.95it/s] \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BhA7dD4RCwnp"},"source":["We aim to generate negative samples such that the dataset is balanced. Therefore, for each message among the positive samples we inspect the entity and append the predicate and the object according to the following strategy: \n","Predicates have a global distribution as well as a local distribution according to the entity they accompany. We want to append a globally frequent, but locally infrequent predicate to each entity in order to emphasize the difference between appropriate and inappropriate entity-predicate combinations. As for the objects, we append the most frequent ones which accompany the chosen predicate.\n","\n","Notes: The object was initially selected based on the distribution according to the selected predicate. However, this leads to learning truth entries instead of relevant entries. Thus, both the subject and the predicate should be incorporated in choosing the object. Distributions based on subject-predicate are scarse for most of the pairs, therefore we sticked to choosing the object based on the distribution according to the subject."]},{"cell_type":"code","metadata":{"id":"iHk9kIO2CwPt","executionInfo":{"status":"ok","timestamp":1603467202609,"user_tz":-180,"elapsed":35510,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"9f6dd087-a038-4763-da63-8c5f5d45a067","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import random\n","\n","neg_candidates = pd.DataFrame(columns=['Message', 'Subject', 'Relation', 'Object', 'Label'])\n","\n","most_frequent_global_relations = [ entry[0] for entry in sorted(globalRelationDict.items(), reverse=True)]\n","\n","def find_negative_predicate(entity):\n","    \n","    most_frequent_local_relations = [entry[0] for entry in sorted(entityToPredicateDict[entity].items(), reverse=True)]\n","    most_frequent_globals_not_in_local = [entry for entry in most_frequent_global_relations if entry not in most_frequent_local_relations]\n","    random_choice_most_frequent = random.choice(most_frequent_globals_not_in_local[:10])\n","    \n","    return random_choice_most_frequent\n","\n","def find_negative_object(positive_object, subject):\n","    \n","    most_frequent_objects = [entry[0] for entry in sorted(subjectToObjectDict[subject].items(), reverse=True)]\n","    \n","    if positive_object in most_frequent_objects:\n","        \n","        most_frequent_objects.remove(positive_object)\n","        \n","    if len(most_frequent_objects) == 0:\n","        \n","        globalObjects = list(train_df[\"Object\"].unique())\n","        \n","        if positive_object in globalObjects:\n","            \n","            globalObjects.remove(positive_object)\n","            \n","            return globalObjects[0]\n","  \n","    return most_frequent_objects[0]\n","    \n","\n","for index, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n","    \n","    message = row[\"Message\"]\n","    subject = row[\"Subject\"]\n","    positive_object = row[\"Object\"] # make sure we do not use the same object for negative sample\n","    label = 0\n","    \n","    negative_predicate = find_negative_predicate(subject)\n","    negative_object = find_negative_object(positive_object, subject)\n","    \n","    neg_candidates = neg_candidates.append({'Message': message, \n","                                            'Subject': subject, \n","                                            'Relation': negative_predicate, \n","                                            'Object': negative_object, \n","                                            'Label': label}, ignore_index=True)\n","    "],"execution_count":20,"outputs":[{"output_type":"stream","text":["100%|██████████| 7827/7827 [00:31<00:00, 251.53it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Kd5sw3HAC0NH","executionInfo":{"status":"ok","timestamp":1603467503786,"user_tz":-180,"elapsed":1041,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["train_df = train_df.append(neg_candidates)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBE_2AZCC-1e"},"source":["##### Random\n","For negative samples we randomly extract entities surrounding the subject-entity that have not been part of the conversation.\n","Start by reading the triple dataset which has the form: *subject relation object*. Initialize every entry as a negative sample.<br>\n","More details: https://github.com/facebookresearch/opendialkg"]},{"cell_type":"code","metadata":{"id":"XJ8L0pOwDKXn"},"source":["triples_df['Relation'] = triples_df['Relation'].apply(lambda x: x[1:] if '~' in x else x)\n","triples_df['Label'] = 0\n","triples_df['Message'] = ''\n","triples_df = triples_df[['Message', 'Subject', 'Relation', 'Object', 'Label']]\n","triples_df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1OdvnIZDNlS"},"source":["For every positive sample $(message, sbj_1, rel_1, obj_1)$ we are looking to sample negative examples $(message, sbj_1, rel_2, obj_2)$ such that $obj_1 \\not= obj_2$.<br>\n","For every positive example, sample *n_samples* negative ones. *Default: 5* <br>\n","*Note:* This cell will take ~15 mins. to run."]},{"cell_type":"code","metadata":{"id":"DAAgXoW0DN5W"},"source":["n_samples = 5\n","neg_candidates = pd.DataFrame(columns=['Message', 'Subject', 'Relation', 'Object', 'Label'])\n","\n","# each message-subject pair may appear multiple times with different objects\n","for message, sbj in tqdm(train_df[['Message', 'Subject']].drop_duplicates().values.tolist()):\n","    # we must make sure that we do not have contradicting entries\n","    objs = train_df[(train_df['Message'] == message) &\n","                    (train_df['Subject'] == sbj)]['Object']\n","    \n","    cand = triples_df[(triples_df['Subject'] == sbj) &\n","                      (~triples_df['Object'].isin(objs))]\n","    cand = cand.sample(min(n_samples, len(cand)))\n","    cand['Message'] = message\n","    \n","    neg_candidates = neg_candidates.append(cand)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gIwyIrw_DSYj"},"source":["train_df = train_df.append(neg_candidates)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emDEF74en2zi"},"source":["### Classifier\n","This block is used to train the classifier. If the classifier is pre-loaded, no need to run it.\n","\n","#### Pre-process data"]},{"cell_type":"code","metadata":{"id":"1I1zSfUi_yWK","executionInfo":{"status":"ok","timestamp":1603470582364,"user_tz":-180,"elapsed":1407,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["if PAIRED_DATA:\n","    col_names = list(train_df.columns)\n","    data_positive = train_df[train_df[\"Label\"] == 1]\n","    data_negative = train_df[train_df[\"Label\"] == 0]\n","    train_df = pd.DataFrame(interleave([data_positive.values, data_negative.values]))\n","    train_df.columns = col_names"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWO09An2n4Ce","executionInfo":{"status":"ok","timestamp":1603470587141,"user_tz":-180,"elapsed":1174,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"f18ede96-eb6b-4a04-9282-a99922490cf1","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["# merge message, subject, relation, object as indicated\n","data = pd.DataFrame()\n","data[\"Message\"] = train_df[\"Message\"] +  \" [SEP] \" + train_df[\"Relation\"] + \" [SEP] \" + train_df[\"Object\"]\n","data[\"Label\"] = train_df[\"Label\"]\n","data.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Message</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Do you like Iron Man [SEP] starred_actors [SEP] Robert Downey Jr.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sure do! Robert Downey Jr. is a favorite. [SEP] starred_actors [SEP] Zodiac (Crime Fiction Film)</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I like crime fiction! Didn't know RDJ was in there. Jake Gyllenhaal starred as well. [SEP] starred_actors [SEP] End of Watch</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>So he did he also starred in End of Watch have you ever seen that movie? [SEP] has_genre [SEP] Thriller</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Do you like Michael Jackson? [SEP] written_by [SEP] Dancing the Dream</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                        Message  Label\n","0                                                             Do you like Iron Man [SEP] starred_actors [SEP] Robert Downey Jr.      1\n","1                              Sure do! Robert Downey Jr. is a favorite. [SEP] starred_actors [SEP] Zodiac (Crime Fiction Film)      1\n","2  I like crime fiction! Didn't know RDJ was in there. Jake Gyllenhaal starred as well. [SEP] starred_actors [SEP] End of Watch      1\n","3                       So he did he also starred in End of Watch have you ever seen that movie? [SEP] has_genre [SEP] Thriller      1\n","4                                                         Do you like Michael Jackson? [SEP] written_by [SEP] Dancing the Dream      1"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"FScOx9tS9XzA","executionInfo":{"status":"ok","timestamp":1603470598781,"user_tz":-180,"elapsed":8691,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"8879b723-65d0-4983-a752-6e8e21b2ba36","colab":{"base_uri":"https://localhost:8080/","height":333}},"source":["# check distribution of tokens in order to set the maximum length of the encoded sequence\n","# this is because bert needs to have the input sequences of the same length. \n","# It uses [PAD] tokens to reach the MAX_LEN \n","token_lens = []\n","\n","for msg in data.Message:\n","  tokens = tokenizer.encode(msg)\n","  token_lens.append(len(tokens))\n","\n","# plot distribution of token lengths  \n","sns.distplot(token_lens)\n","plt.xlim([0, 256]);\n","plt.xlabel('Token count');  "],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"2f_f_aKv9YTG","executionInfo":{"status":"ok","timestamp":1603470601635,"user_tz":-180,"elapsed":1333,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["MAX_LEN = 65"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6GpHn-b_1B-","executionInfo":{"status":"ok","timestamp":1603470601636,"user_tz":-180,"elapsed":704,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# split into train, validation and test\n","if PAIRED_DATA:\n","  data_train, data_val, data_test = np.split(data, [int(.8 * len(data)), int(.9 * len(data))])\n","else:  \n","  data_train, data_test = train_test_split(data, test_size=0.2, shuffle=True, random_state=RANDOM_SEED)\n","  data_val, data_test = train_test_split(data_test, test_size=0.5, shuffle=True, random_state=RANDOM_SEED)\n","\n","if ONLY_POSITIVE_TEST:\n","  data_val = data_val[data_val[\"Label\"] == 1]\n","  data_test = data_test[data_test[\"Label\"] == 1]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0MX_eZq9cKm","executionInfo":{"status":"ok","timestamp":1603470604288,"user_tz":-180,"elapsed":1215,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# helper class for storing the data\n","class OpenDialKGDataset(Dataset):\n","  def __init__(self, messages, labels, tokenizer, max_len):\n","    self.messages = messages\n","    self.labels = labels\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","  \n","  def __len__(self):\n","    return len(self.messages)\n","  \n","  def __getitem__(self, item):\n","    message = str(self.messages[item])\n","    label = self.labels[item]\n","\n","    encoding = self.tokenizer.encode_plus(\n","      message,\n","      add_special_tokens=True,\n","      max_length=self.max_len,\n","      return_token_type_ids=False,\n","      pad_to_max_length=True,\n","      return_attention_mask=True,\n","      truncation=True,\n","      return_tensors='pt',\n","    )\n","\n","    return {\n","      'message': message,\n","      'input_ids': encoding['input_ids'].flatten(),\n","      'attention_mask': encoding['attention_mask'].flatten(),\n","      'label': torch.tensor(label, dtype=torch.long)\n","    }\n","\n","\n","# loader function for the above class\n","def create_data_loader(df, tokenizer, max_len=65, batch_size=16):\n","  dataset = OpenDialKGDataset( messages=df.Message.to_numpy(), \n","                         labels=df.Label.to_numpy(), \n","                         tokenizer=tokenizer,\n","                         max_len=max_len)\n","\n","  return DataLoader(dataset, batch_size=batch_size)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_gl4-Og9tAs","executionInfo":{"status":"ok","timestamp":1603470606087,"user_tz":-180,"elapsed":866,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def train_epoch(model, data_loader, loss_fn, optimizer, device, n_examples):\n","  true_labels_list = []\n","  predicted_labels_list = []\n","  model = model.train()\n","\n","  losses = []\n","  correct_predictions = 0\n","  \n","  for i,d in enumerate(data_loader):\n","    optimizer.zero_grad()\n","\n","    input_ids = d[\"input_ids\"].to(device)\n","    attention_mask = d[\"attention_mask\"].to(device)\n","    labels = d[\"label\"].to(device)\n","\n","    outputs = model(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    _, preds = torch.max(outputs, dim=1)\n","\n","    true_labels = labels.cpu().numpy()\n","    predicted_labels = outputs[:, 1].detach().cpu().numpy()\n","    predicted_args = preds.cpu().numpy()\n","\n","    true_labels_list = true_labels_list + true_labels.tolist()\n","    predicted_labels_list = predicted_labels_list + predicted_labels.tolist()\n","\n","    loss = loss_fn(outputs, labels)\n","\n","    correct_predictions += torch.sum(preds == labels)\n","\n","    losses.append(loss.item())\n","    if (i%100==0):\n","      print(f\"{i} out of {len(train_data_loader)}\")\n","\n","    loss.backward()\n","    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","    optimizer.step()\n","\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses), true_labels_list, predicted_labels_list"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZDByUjuJ9yRZ","executionInfo":{"status":"ok","timestamp":1603470608562,"user_tz":-180,"elapsed":1123,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","  model = model.eval()\n","\n","  losses = []\n","  correct_predictions = 0\n","  true_labels_list = []\n","  predicted_labels_list = []\n","  predicted_args_list = []\n","\n","  with torch.no_grad():\n","    for i, d in enumerate(data_loader):\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      labels = d[\"label\"].to(device)\n","\n","      outputs = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask\n","      )\n","      \n","      _, preds = torch.max(outputs, dim=1)\n","\n","      true_labels = labels.cpu().numpy()\n","      predicted_labels = outputs[:, 1].cpu().numpy()\n","      predicted_args = preds.cpu().numpy()\n","\n","      true_labels_list = true_labels_list + true_labels.tolist()\n","      predicted_labels_list = predicted_labels_list + predicted_labels.tolist()\n","      predicted_args_list = predicted_args_list + predicted_args.tolist()\n","\n","      loss = loss_fn(outputs, labels)\n","\n","      correct_predictions += torch.sum(preds == labels)\n","\n","      losses.append(loss.item())\n","\n","\n","  return correct_predictions.double() / n_examples, np.mean(losses), true_labels_list, predicted_labels_list, predicted_args_list"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNwJtFTAHWpk","executionInfo":{"status":"ok","timestamp":1603470612110,"user_tz":-180,"elapsed":1071,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["BATCH_SIZE = 16\n","\n","train_data_loader = create_data_loader(data_train, tokenizer, MAX_LEN, BATCH_SIZE)\n","val_data_loader = create_data_loader(data_val, tokenizer, MAX_LEN, BATCH_SIZE)\n","test_data_loader = create_data_loader(data_test, tokenizer, MAX_LEN, BATCH_SIZE) "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPJHKwkAAyAO","executionInfo":{"status":"ok","timestamp":1603470655303,"user_tz":-180,"elapsed":1213,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["EPOCHS = 1\n","\n","optimizer = AdamW(classifier.parameters(), lr=2e-5, correct_bias=False)\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","loss_fn = nn.CrossEntropyLoss().to(device)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AT4QvWC92VN","executionInfo":{"status":"ok","timestamp":1603470771775,"user_tz":-180,"elapsed":114520,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"8a731e43-352d-4afe-8fbe-dd9eb572ec83","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["best_accuracy = 0\n","\n","for epoch in range(EPOCHS):\n","  print(f'Epoch {epoch + 1}/{EPOCHS}')\n","  print('----------')\n","\n","  train_acc, train_loss, train_tl, train_pl = train_epoch(classifier, train_data_loader, loss_fn, optimizer, device, len(data_train))\n","  print(f'Train loss = {train_loss},  Accuracy =  {train_acc}')\n","\n","  val_acc, val_loss, true_labels, predicted_labels, predicted_args = eval_model(classifier, val_data_loader, loss_fn, device, len(data_val))\n","  print(f'Validation loss = {val_loss},  Accuracy {val_acc}')\n","  \n","  print()\n","\n","  if val_acc > best_accuracy:\n","    torch.save(classifier.state_dict(), 'best_model_state.bin')\n","    best_accuracy = val_acc"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","----------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["0 out of 783\n","100 out of 783\n","200 out of 783\n","300 out of 783\n","400 out of 783\n","500 out of 783\n","600 out of 783\n","700 out of 783\n","Train loss = 0.4319654333941629,  Accuracy =  0.8812300319488818\n","Validation loss = 0.40592806710272417,  Accuracy 0.9073482428115016\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EyfkL_Z9-1nj","executionInfo":{"status":"ok","timestamp":1603470777549,"user_tz":-180,"elapsed":5762,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"740758ac-f6e7-48e8-98ad-b62093192450","colab":{"base_uri":"https://localhost:8080/","height":87}},"source":["test_acc, _, true_labels, predicted_scores, predicted_labels = eval_model(classifier, test_data_loader, loss_fn, device, len(data_test))\n","\n","test_acc.item()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.9150159744408946"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"JaY5AfY09_2s"},"source":["#### Classifier Results"]},{"cell_type":"code","metadata":{"id":"6mS3J44S-BPp","executionInfo":{"status":"ok","timestamp":1603470781252,"user_tz":-180,"elapsed":2289,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"7e969187-a795-4c4d-b299-020e04621180","colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["fpr, tpr, thresholds = roc_curve(np.asarray(true_labels), np.asarray(predicted_scores), pos_label=1)\n","auc = np.trapz(tpr,fpr)\n","plt.plot(fpr,tpr, color='darkorange', lw = 2, label='ROC curve', clip_on=False)\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC curve, AUC = %.2f'%auc)\n","plt.legend()\n","plt.show() "],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-3MC6ydh-Og0","executionInfo":{"status":"ok","timestamp":1603467918033,"user_tz":-180,"elapsed":1076,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["#Let's look at the false positive and false negative cases\n","\"\"\"\n","1. False positive: Get indices where pred_label = 1 and true_label = 0\n","2. False negative: Get indices where pred_label = 0 and true_label = 1\n","\"\"\"\n","false_positives = [0] * len(true_labels)\n","false_negatives = [0] * len(true_labels)\n","tp, tn = 0, 0\n","\n","for i in range(len(true_labels)):\n","  if true_labels[i] == 1 and predicted_labels[i] == 1:\n","    tp += 1\n","  if true_labels[i] ==0 and predicted_labels[i] ==0:\n","    tn += 1\n","  if true_labels[i] == 0 and predicted_labels[i] == 1:\n","    false_positives[i] = 1\n","  if true_labels[i] == 1 and predicted_labels[i] == 0:\n","    false_negatives[i] = 1  \n","\n","dataset_fp = data_test.iloc[np.where(false_positives)[0].tolist()]\n","dataset_fn = data_test.iloc[np.where(false_negatives)[0].tolist()]"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIH5Pyus-bDG","executionInfo":{"status":"ok","timestamp":1603467922469,"user_tz":-180,"elapsed":1675,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["import seaborn\n","import matplotlib.pyplot as plt\n"," \n"," \n","def plot_confusion_matrix(data, labels, output_filename):\n","    \"\"\"Plot confusion matrix using heatmap.\n"," \n","    Args:\n","        data (list of list): List of lists with confusion matrix data.\n","        labels (list): Labels which will be plotted across x and y axis.\n","        output_filename (str): Path to output file.\n"," \n","    \"\"\"\n","    seaborn.set(color_codes=True)\n","    plt.figure(1, figsize=(9, 6))\n"," \n","    plt.title(\"Confusion Matrix\", fontsize=16)\n"," \n","    seaborn.set(font_scale=1.4)\n","    ax = seaborn.heatmap(data, annot=True, cmap=\"Blues\", cbar=False)\n"," \n","    ax.set_xticklabels(labels)\n","    ax.set_yticklabels(labels)\n"," \n","    ax.set(ylabel=\"True Label\", xlabel=\"Predicted Label\")\n"," \n","    plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n","    plt.close()\n"," \n","# define data\n","total = (tp + tn + len(dataset_fn) + len(dataset_fp)) / 100\n","data = [[tp / total, len(dataset_fn) / total],\n","        [len(dataset_fp) / total , tn / total]]\n"," \n","# define labels\n","labels = [\"Relevant\", \"Irrelevant\"]\n"," \n","# create confusion matrix\n","plot_confusion_matrix(data, labels, \"confusion_matrix.png\")"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvl6uorA-TXz","executionInfo":{"status":"ok","timestamp":1603468183267,"user_tz":-180,"elapsed":1412,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"30d7004f-2d5e-47ca-dd04-9a8274185bda","colab":{"base_uri":"https://localhost:8080/","height":332}},"source":["#Classification threshold\n","score = []\n","\n","for label in predicted_labels:\n","  score.append(max(label, 1-label))\n","\n","plt.ylim((0, 1.1))\n","plt.plot(score, c='orange')\n","plt.title(\"Classifier Confidence Scores\")\n","plt.xlabel(\"Test Sequences\")\n","plt.ylabel(\"Prediction Score\")"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, 'Prediction Score')"]},"metadata":{"tags":[]},"execution_count":63},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"WBT7toW7n4TB"},"source":["### DialoGPT\n","\n","This section is used to finetune the GPT-2 model on the OpenDialKG dataset (can be skipped if *finetuned_model.bin* is available)\n","\n","To finetune the model we followed the following tutorial by  Rostyslav Neskorozhenyi <br> \n","Article: https://towardsdatascience.com/make-your-own-rick-sanchez-bot-with-transformers-and-dialogpt-fine-tuning-f85e6d1f4e30 <br>\n","Code: https://colab.research.google.com/drive/15wa925dj7jvdvrz8_z3vU7btqAFQLVlG"]},{"cell_type":"markdown","metadata":{"id":"Y7tJjVmNEKXG"},"source":["#### Data preparation"]},{"cell_type":"markdown","metadata":{"id":"qB1ghBC6ERMo"},"source":["Please run the Data Prepation block above such that *opendialkg* is built. "]},{"cell_type":"code","metadata":{"id":"Gn_mbCdPn6OH","executionInfo":{"status":"ok","timestamp":1603468203135,"user_tz":-180,"elapsed":1415,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"83565d5f-63e8-4e69-d32e-12e8803123d0","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["finetune_df = []\n","\n","for i in opendialkg:\n","  for j in range(0, len(opendialkg[i]) - 1):\n","    response = opendialkg[i][j+1][0] if (type(opendialkg[i][j+1]) == tuple) else opendialkg[i][j+1]\n","    context = opendialkg[i][j][0] if (type(opendialkg[i][j]) == tuple) else opendialkg[i][j]\n","    finetune_df.append({'response': response,\n","                        'context': context,\n","    })\n","\n","finetune_df = pd.DataFrame(finetune_df)\n","finetune_df"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>response</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sure do! Robert Downey Jr. is a favorite.</td>\n","      <td>Do you like Iron Man</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yes i like him too did you know he also was in...</td>\n","      <td>Sure do! Robert Downey Jr. is a favorite.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I like crime fiction! Didn't know RDJ was in t...</td>\n","      <td>Yes i like him too did you know he also was in...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>So he did he also starred in End of Watch have...</td>\n","      <td>I like crime fiction! Didn't know RDJ was in t...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Yes I have! I like films directed by David Aye...</td>\n","      <td>So he did he also starred in End of Watch have...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>29384</th>\n","      <td>Another recommendation is The Legend of Hercules.</td>\n","      <td>That's a good one! Do you know of any others?</td>\n","    </tr>\n","    <tr>\n","      <th>29385</th>\n","      <td>I haven't seen that one, do you know who stars...</td>\n","      <td>Another recommendation is The Legend of Hercules.</td>\n","    </tr>\n","    <tr>\n","      <th>29386</th>\n","      <td>Kellan Lutz stars in the film.</td>\n","      <td>I haven't seen that one, do you know who stars...</td>\n","    </tr>\n","    <tr>\n","      <th>29387</th>\n","      <td>Oh alright! I think I'm sold on that one, than...</td>\n","      <td>Kellan Lutz stars in the film.</td>\n","    </tr>\n","    <tr>\n","      <th>29388</th>\n","      <td>You are welcome.</td>\n","      <td>Oh alright! I think I'm sold on that one, than...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>29389 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                response                                            context\n","0              Sure do! Robert Downey Jr. is a favorite.                               Do you like Iron Man\n","1      Yes i like him too did you know he also was in...          Sure do! Robert Downey Jr. is a favorite.\n","2      I like crime fiction! Didn't know RDJ was in t...  Yes i like him too did you know he also was in...\n","3      So he did he also starred in End of Watch have...  I like crime fiction! Didn't know RDJ was in t...\n","4      Yes I have! I like films directed by David Aye...  So he did he also starred in End of Watch have...\n","...                                                  ...                                                ...\n","29384  Another recommendation is The Legend of Hercules.      That's a good one! Do you know of any others?\n","29385  I haven't seen that one, do you know who stars...  Another recommendation is The Legend of Hercules.\n","29386                     Kellan Lutz stars in the film.  I haven't seen that one, do you know who stars...\n","29387  Oh alright! I think I'm sold on that one, than...                     Kellan Lutz stars in the film.\n","29388                                   You are welcome.  Oh alright! I think I'm sold on that one, than...\n","\n","[29389 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"xCnVY-fEF26U","executionInfo":{"status":"ok","timestamp":1603468207727,"user_tz":-180,"elapsed":1369,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def construct_conv(row, tokenizer, eos = True):\n","    flatten = lambda l: [item for sublist in l for item in sublist]\n","    conv = list(reversed([tokenizer.encode(x) + [tokenizer.eos_token_id] for x in row]))\n","    conv = flatten(conv)\n","    return conv\n","\n","class ConversationDataset(Dataset):\n","    def __init__(self, tokenizer: PreTrainedTokenizer, args, df, block_size=512):\n","\n","        block_size = block_size - (tokenizer.max_len - tokenizer.max_len_single_sentence)\n","\n","        directory = args.cache_dir\n","        cached_features_file = os.path.join(\n","            directory, args.model_type + \"_cached_lm_\" + str(block_size)\n","        )\n","\n","        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n","            logger.info(\"Loading features from cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"rb\") as handle:\n","                self.examples = pickle.load(handle)\n","        else:\n","            logger.info(\"Creating features from dataset file at %s\", directory)\n","\n","            self.examples = []\n","            for _, row in df.iterrows():\n","                conv = construct_conv(row, tokenizer)\n","                self.examples.append(conv)\n","\n","            logger.info(\"Saving features into cached file %s\", cached_features_file)\n","            with open(cached_features_file, \"wb\") as handle:\n","                pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    def __len__(self):\n","        return len(self.examples)\n","\n","    def __getitem__(self, item):\n","        return torch.tensor(self.examples[item], dtype=torch.long)"],"execution_count":65,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQLtQQ32F3y-"},"source":["#### Training"]},{"cell_type":"code","metadata":{"id":"yasGvL4HF5II","executionInfo":{"status":"ok","timestamp":1603468213551,"user_tz":-180,"elapsed":1148,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["\"\"\"\n","Fine-tuning the library models for language modeling on a text file (GPT, GPT-2, BERT, RoBERTa).\n","GPT and GPT-2 are fine-tuned using a causal language modeling (CLM) loss while BERT and RoBERTa are fine-tuned\n","using a masked language modeling (MLM) loss.\n","\"\"\"\n","\n","import glob\n","import logging\n","import os\n","import pickle\n","import random\n","import re\n","import shutil\n","from typing import Dict, List, Tuple\n","\n","import pandas as pd\n","import numpy as np\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm.notebook import tqdm, trange\n","\n","from pathlib import Path\n","\n","from transformers import (\n","    MODEL_WITH_LM_HEAD_MAPPING,\n","    WEIGHTS_NAME,\n","    AdamW,\n","    AutoConfig,\n","    AutoModelWithLMHead,\n","    AutoTokenizer,\n","    PreTrainedModel,\n","    PreTrainedTokenizer,\n","    get_linear_schedule_with_warmup,\n",")\n","\n","\n","try:\n","    from torch.utils.tensorboard import SummaryWriter\n","except ImportError:\n","    from tensorboardX import SummaryWriter\n","\n","# Configs\n","logger = logging.getLogger(__name__)\n","\n","MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n","MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"],"execution_count":66,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y6adUQQTF69X","executionInfo":{"status":"ok","timestamp":1603468215983,"user_tz":-180,"elapsed":1193,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# Args to allow for easy convertion of python script to notebook\n","class Args():\n","    def __init__(self):\n","        self.output_dir = 'output-finetuned'\n","        self.model_type = 'gpt2'\n","        self.model_name_or_path = 'microsoft/DialoGPT-medium'\n","        self.config_name = 'microsoft/DialoGPT-medium'\n","        self.tokenizer_name = 'microsoft/DialoGPT-medium'\n","        self.cache_dir = 'cached'\n","        self.block_size = 512\n","        self.do_train = True\n","        self.do_eval = True\n","        self.evaluate_during_training = False\n","        self.per_gpu_train_batch_size = 4\n","        self.per_gpu_eval_batch_size = 4\n","        self.gradient_accumulation_steps = 1\n","        self.learning_rate = 5e-5\n","        self.weight_decay = 0.0\n","        self.adam_epsilon = 1e-8\n","        self.max_grad_norm = 1.0\n","        self.num_train_epochs = 3\n","        self.max_steps = -1\n","        self.warmup_steps = 0\n","        self.logging_steps = 1000\n","        self.save_steps = 3500\n","        self.save_total_limit = None\n","        self.eval_all_checkpoints = False\n","        self.no_cuda = False\n","        self.overwrite_output_dir = True\n","        self.overwrite_cache = True\n","        self.should_continue = False\n","        self.seed = 42\n","        self.local_rank = -1\n","        self.fp16 = False\n","        self.fp16_opt_level = 'O1'\n","\n","args = Args()"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxseoW6eF77-","executionInfo":{"status":"ok","timestamp":1603468217259,"user_tz":-180,"elapsed":728,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# Cacheing and storing of data/checkpoints\n","\n","def load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False):\n","    return ConversationDataset(tokenizer, args, df_val if evaluate else df_trn)\n","\n","\n","def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    if args.n_gpu > 0:\n","        torch.cuda.manual_seed_all(args.seed)\n","\n","\n","def _sorted_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> List[str]:\n","    ordering_and_checkpoint_path = []\n","\n","    glob_checkpoints = glob.glob(os.path.join(args.output_dir, \"{}-*\".format(checkpoint_prefix)))\n","\n","    for path in glob_checkpoints:\n","        if use_mtime:\n","            ordering_and_checkpoint_path.append((os.path.getmtime(path), path))\n","        else:\n","            regex_match = re.match(\".*{}-([0-9]+)\".format(checkpoint_prefix), path)\n","            if regex_match and regex_match.groups():\n","                ordering_and_checkpoint_path.append((int(regex_match.groups()[0]), path))\n","\n","    checkpoints_sorted = sorted(ordering_and_checkpoint_path)\n","    checkpoints_sorted = [checkpoint[1] for checkpoint in checkpoints_sorted]\n","    return checkpoints_sorted\n","\n","\n","def _rotate_checkpoints(args, checkpoint_prefix=\"checkpoint\", use_mtime=False) -> None:\n","    if not args.save_total_limit:\n","        return\n","    if args.save_total_limit <= 0:\n","        return\n","\n","    # Check if we should delete older checkpoint(s)\n","    checkpoints_sorted = _sorted_checkpoints(args, checkpoint_prefix, use_mtime)\n","    if len(checkpoints_sorted) <= args.save_total_limit:\n","        return\n","\n","    number_of_checkpoints_to_delete = max(0, len(checkpoints_sorted) - args.save_total_limit)\n","    checkpoints_to_be_deleted = checkpoints_sorted[:number_of_checkpoints_to_delete]\n","    for checkpoint in checkpoints_to_be_deleted:\n","        logger.info(\"Deleting older checkpoint [{}] due to args.save_total_limit\".format(checkpoint))\n","        shutil.rmtree(checkpoint)"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8_aICcDF9x9","executionInfo":{"status":"ok","timestamp":1603468219899,"user_tz":-180,"elapsed":1311,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def train(args, train_dataset, model: PreTrainedModel, tokenizer: PreTrainedTokenizer) -> Tuple[int, float]:\n","    \"\"\" Train the model \"\"\"\n","    if args.local_rank in [-1, 0]:\n","        tb_writer = SummaryWriter()\n","\n","    args.train_batch_size = args.per_gpu_train_batch_size * max(1, args.n_gpu)\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n","    train_dataloader = DataLoader(\n","        train_dataset, sampler=train_sampler, batch_size=args.train_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    if args.max_steps > 0:\n","        t_total = args.max_steps\n","        args.num_train_epochs = args.max_steps // (len(train_dataloader) // args.gradient_accumulation_steps) + 1\n","    else:\n","        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","\n","    model = model.module if hasattr(model, \"module\") else model  # Take care of distributed/parallel training\n","    model.resize_token_embeddings(len(tokenizer))\n","    # add_special_tokens_(model, tokenizer)\n","\n","\n","    # Prepare optimizer and schedule (linear warmup and decay)\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","    )\n","\n","    # Check if saved optimizer or scheduler states exist\n","    if (\n","        args.model_name_or_path\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"optimizer.pt\"))\n","        and os.path.isfile(os.path.join(args.model_name_or_path, \"scheduler.pt\"))\n","    ):\n","        # Load in optimizer and scheduler states\n","        optimizer.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"optimizer.pt\")))\n","        scheduler.load_state_dict(torch.load(os.path.join(args.model_name_or_path, \"scheduler.pt\")))\n","\n","    if args.fp16:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n","\n","    # multi-gpu training (should be after apex fp16 initialization)\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Distributed training (should be after apex fp16 initialization)\n","    if args.local_rank != -1:\n","        model = torch.nn.parallel.DistributedDataParallel(\n","            model, device_ids=[args.local_rank], output_device=args.local_rank, find_unused_parameters=True\n","        )\n","\n","    # Train!\n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n","    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n","    logger.info(\n","        \"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n","        args.train_batch_size\n","        * args.gradient_accumulation_steps\n","        * (torch.distributed.get_world_size() if args.local_rank != -1 else 1),\n","    )\n","    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    epochs_trained = 0\n","    steps_trained_in_current_epoch = 0\n","    # Check if continuing training from a checkpoint\n","    if args.model_name_or_path and os.path.exists(args.model_name_or_path):\n","        try:\n","            # set global_step to gobal_step of last saved checkpoint from model path\n","            checkpoint_suffix = args.model_name_or_path.split(\"-\")[-1].split(\"/\")[0]\n","            global_step = int(checkpoint_suffix)\n","            epochs_trained = global_step // (len(train_dataloader) // args.gradient_accumulation_steps)\n","            steps_trained_in_current_epoch = global_step % (len(train_dataloader) // args.gradient_accumulation_steps)\n","\n","            logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n","            logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n","            logger.info(\"  Continuing training from global step %d\", global_step)\n","            logger.info(\"  Will skip the first %d steps in the first epoch\", steps_trained_in_current_epoch)\n","        except ValueError:\n","            logger.info(\"  Starting fine-tuning.\")\n","\n","    tr_loss, logging_loss = 0.0, 0.0\n","\n","    model.zero_grad()\n","    train_iterator = trange(\n","        epochs_trained, int(args.num_train_epochs), desc=\"Epoch\", disable=args.local_rank not in [-1, 0]\n","    )\n","    set_seed(args)  # Added here for reproducibility\n","    for _ in train_iterator:\n","        epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", disable=args.local_rank not in [-1, 0])\n","        for step, batch in enumerate(epoch_iterator):\n","\n","            # Skip past any already trained steps if resuming training\n","            if steps_trained_in_current_epoch > 0:\n","                steps_trained_in_current_epoch -= 1\n","                continue\n","\n","            inputs, labels = (batch, batch)\n","            if inputs.shape[1] > 1024: continue\n","            inputs = inputs.to(args.device)\n","            labels = labels.to(args.device)\n","            model.train()\n","            outputs = model(inputs, labels=labels)\n","            loss = outputs[0]  # model outputs are always tuple in transformers (see doc)\n","\n","            if args.n_gpu > 1:\n","                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n","            if args.gradient_accumulation_steps > 1:\n","                loss = loss / args.gradient_accumulation_steps\n","\n","            if args.fp16:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","            else:\n","                loss.backward()\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args.gradient_accumulation_steps == 0:\n","                if args.fp16:\n","                    torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args.max_grad_norm)\n","                else:\n","                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","                optimizer.step()\n","                scheduler.step()  # Update learning rate schedule\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args.local_rank in [-1, 0] and args.logging_steps > 0 and global_step % args.logging_steps == 0:\n","                    # Log metrics\n","                    if (\n","                        args.local_rank == -1 and args.evaluate_during_training\n","                    ):  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(args, model, tokenizer)\n","                        for key, value in results.items():\n","                            tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)\n","                    tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)\n","                    tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)\n","                    logging_loss = tr_loss\n","\n","                if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:\n","                    checkpoint_prefix = \"checkpoint\"\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args.output_dir, \"{}-{}\".format(checkpoint_prefix, global_step))\n","                    os.makedirs(output_dir, exist_ok=True)\n","                    model_to_save = (\n","                        model.module if hasattr(model, \"module\") else model\n","                    )  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    tokenizer.save_pretrained(output_dir)\n","\n","                    torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","                    _rotate_checkpoints(args, checkpoint_prefix)\n","\n","                    torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n","                    torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n","                    logger.info(\"Saving optimizer and scheduler states to %s\", output_dir)\n","\n","            if args.max_steps > 0 and global_step > args.max_steps:\n","                epoch_iterator.close()\n","                break\n","        if args.max_steps > 0 and global_step > args.max_steps:\n","            train_iterator.close()\n","            break\n","\n","    if args.local_rank in [-1, 0]:\n","        tb_writer.close()\n","\n","    return global_step, tr_loss / global_step\n","\n","# Evaluation of some model\n","\n","def evaluate(args, model: PreTrainedModel, tokenizer: PreTrainedTokenizer, df_trn, df_val, prefix=\"\") -> Dict:\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args.output_dir\n","\n","    eval_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=True)\n","    os.makedirs(eval_output_dir, exist_ok=True)\n","    args.eval_batch_size = args.per_gpu_eval_batch_size * max(1, args.n_gpu)\n","    # Note that DistributedSampler samples randomly\n","\n","    def collate(examples: List[torch.Tensor]):\n","        if tokenizer._pad_token is None:\n","            return pad_sequence(examples, batch_first=True)\n","        return pad_sequence(examples, batch_first=True, padding_value=tokenizer.pad_token_id)\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(\n","        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate, drop_last = True\n","    )\n","\n","    # multi-gpu evaluate\n","    if args.n_gpu > 1:\n","        model = torch.nn.DataParallel(model)\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    model.eval()\n","\n","    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","        inputs, labels = (batch, batch)\n","        inputs = inputs.to(args.device)\n","        labels = labels.to(args.device)\n","\n","        with torch.no_grad():\n","            outputs = model(inputs, labels=labels)\n","            lm_loss = outputs[0]\n","            eval_loss += lm_loss.mean().item()\n","        nb_eval_steps += 1\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    perplexity = torch.exp(torch.tensor(eval_loss))\n","\n","    result = {\"perplexity\": perplexity}\n","\n","    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return result"],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wmmduom2GDu3"},"source":["#### Run"]},{"cell_type":"code","metadata":{"id":"MNMvuE0OGAHf","executionInfo":{"status":"ok","timestamp":1603468225634,"user_tz":-180,"elapsed":1740,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["# Main runner\n","def main(df_trn, df_val):\n","    args = Args()\n","    \n","    if args.should_continue:\n","        sorted_checkpoints = _sorted_checkpoints(args)\n","        if len(sorted_checkpoints) == 0:\n","            raise ValueError(\"Used --should_continue but no checkpoint was found in --output_dir.\")\n","        else:\n","            args.model_name_or_path = sorted_checkpoints[-1]\n","\n","    if (\n","        os.path.exists(args.output_dir)\n","        and os.listdir(args.output_dir)\n","        and args.do_train\n","        and not args.overwrite_output_dir\n","        and not args.should_continue\n","    ):\n","        raise ValueError(\n","            \"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(\n","                args.output_dir\n","            )\n","        )\n","\n","    # Setup CUDA, GPU & distributed training\n","    device = torch.device(\"cuda\")\n","    args.n_gpu = torch.cuda.device_count()\n","    args.device = device\n","\n","    # Setup logging\n","    logging.basicConfig(\n","        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n","        datefmt=\"%m/%d/%Y %H:%M:%S\",\n","        level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n","    )\n","    logger.warning(\n","        \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n","        args.local_rank,\n","        device,\n","        args.n_gpu,\n","        bool(args.local_rank != -1),\n","        args.fp16,\n","    )\n","\n","    # Set seed\n","    set_seed(args)\n","\n","    config = AutoConfig.from_pretrained(args.config_name, cache_dir=args.cache_dir)\n","    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name, cache_dir=args.cache_dir)\n","    model = AutoModelWithLMHead.from_pretrained(\n","        args.model_name_or_path,\n","        from_tf=False,\n","        config=config,\n","        cache_dir=args.cache_dir,\n","    )\n","    model.to(args.device)\n","    \n","    logger.info(\"Training/evaluation parameters %s\", args)\n","\n","    # Training\n","    if args.do_train:\n","        train_dataset = load_and_cache_examples(args, tokenizer, df_trn, df_val, evaluate=False)\n","\n","        global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n","        logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n","\n","    # Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()\n","    if args.do_train:\n","        # Create output directory if needed\n","        os.makedirs(args.output_dir, exist_ok=True)\n","\n","        logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n","        # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","        # They can then be reloaded using `from_pretrained()`\n","        model_to_save = (\n","            model.module if hasattr(model, \"module\") else model\n","        )  # Take care of distributed/parallel training\n","        model_to_save.save_pretrained(args.output_dir)\n","        tokenizer.save_pretrained(args.output_dir)\n","\n","        # Good practice: save your training arguments together with the trained model\n","        torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n","\n","        # Load a trained model and vocabulary that you have fine-tuned\n","        model = AutoModelWithLMHead.from_pretrained(args.output_dir)\n","        tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n","        model.to(args.device)\n","\n","    # Evaluation\n","    results = {}\n","    if args.do_eval and args.local_rank in [-1, 0]:\n","        checkpoints = [args.output_dir]\n","        if args.eval_all_checkpoints:\n","            checkpoints = list(\n","                os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + \"/**/\" + WEIGHTS_NAME, recursive=True))\n","            )\n","            logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging\n","        logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n","        for checkpoint in checkpoints:\n","            global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n","            prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n","\n","            model = AutoModelWithLMHead.from_pretrained(checkpoint)\n","            model.to(args.device)\n","            result = evaluate(args, model, tokenizer, df_trn, df_val, prefix=prefix)\n","            result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n","            results.update(result)\n","\n","    return results, model"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrS_j7X9GFzZ","executionInfo":{"status":"error","timestamp":1603468695115,"user_tz":-180,"elapsed":462451,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"7659986c-5c2e-4e2a-ffad-f8917a65049a","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["53911d72e0fa477c877f68de3e288339","6c83335ab6934c339b61f943ff9dc05e","a10b5c8f60cf4c9fb6b9d4935879d6b0","cda385fdc6f047f580d9c0fabe68155d","0daa32cdc0a8468ea1ed8f0ec4ffec11","41cb63ff363e46aa93c95c96dff7514e","fb72ea6c9b2e49d09da9719e7f1f201b","f45013a6d2a9450fb2d77bd8ce626d0e","105ded7338954c36b3ecd845c245c2fa","2482088589b5413e9ae8bf90cfa4649a","acf4eadbc9694062aa63701dd7092e8a","b72dec3dd5eb4bebb830986f12d26163","d2e420a58483450fbbe213dcfb49fcf7","297ae016bb2d437abf78a9f6735e3b2a","295b10baa8fa4629bf222c7bdbafba53","c4a21674971544b8bb1b1dbb3a35d328","4dab46530f6749218f7eb8dd916c1190","189804e9b11c41a99d4584b935de759c","97b416efe9334044b5a9a2ef18591ea8","be62fdc8776d493bac7cea4fbb0c4aa5","9bbc015a08d3407e8efeb4d55514d0fb","b743d9fd8faf47bab809e2b04cb8f1f1","3d1f2ec87be1411c8d09d4a4e7863a80","06633637d89e43598bf06e3cf2daf1fa","e4307ee8b1dc4da48c87eb89a7de9c2a","0fce6d5fbb0e407dae5fd60397ff1512","916de07769624e8485d31adc9719ce69","cadf18220b92433ba52e85d6568080a9","9e0c0b744f4e4b429edca3be16b134f0","34bfdd5d53314d7b84cfa0e10f7f2961","1cebcf9cf1af4e949d1fd68a472463af","8c6951f607e44e1cb6a2d098816b5453","1b58ea3b210d4a25ad662c6a5596433e","7b80dbf2c78c496aa47ef69b889fe4ef","4e129a8caa8e4207b8a63471ffefb648","e4ffd186bb134ea6a084df71ebd75862","c428b04d9f4b4f259cfa7f286326372f","2f811eb77e254d3ab359fd027f05f104","bcdc84746df24acbb9f2bc80123458e6","c47657371fff4ad3966b31777ed04516","784565a1ba054a87ac3f3fbfb4f8d61f","490e217f758e427781158e7ebd12264b","0dfcdbad69dd428e94abf492d690955c","c69474a30a7e4f13b148694a2a7785a8","1017ac86f464483a8e0f6c5797cd91f9","f5339846004d46d98e6186563658d9f5","f5facdd353e248f2a15b1bca7a1626e3","c02cdd08d62543d3b713eb04025b9d4b"]}},"source":["trn_df, val_df = train_test_split(finetune_df, test_size = 0.1)\n","main(trn_df, val_df)\n","generator_model = AutoModelWithLMHead.from_pretrained(FINETUNED_MODEL)\n","generator_tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)"],"execution_count":71,"outputs":[{"output_type":"stream","text":["10/23/2020 15:50:32 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","10/23/2020 15:50:33 - INFO - filelock -   Lock 140203072038728 acquired on cached/8833f19dc2d2e7283d03d94f879e592e5512320f1a1f2c02f0365e8083441740.92596f8e95f12e3301753009c5c280b3d6e4f5861fcda63c97cf496529703153.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"53911d72e0fa477c877f68de3e288339","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["10/23/2020 15:50:33 - INFO - filelock -   Lock 140203072038728 released on cached/8833f19dc2d2e7283d03d94f879e592e5512320f1a1f2c02f0365e8083441740.92596f8e95f12e3301753009c5c280b3d6e4f5861fcda63c97cf496529703153.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["10/23/2020 15:50:34 - INFO - filelock -   Lock 140203072038280 acquired on cached/160770c7e6068191582afd6748b1f7e8395a4e6e63264fa390d534c6e25184b9.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"105ded7338954c36b3ecd845c245c2fa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["10/23/2020 15:50:35 - INFO - filelock -   Lock 140203072038280 released on cached/160770c7e6068191582afd6748b1f7e8395a4e6e63264fa390d534c6e25184b9.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["10/23/2020 15:50:35 - INFO - filelock -   Lock 140203072037776 acquired on cached/2768fc6cab7211630a47d239a3c467e01b5edcc650491f3777f181979ed61486.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4dab46530f6749218f7eb8dd916c1190","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["10/23/2020 15:50:36 - INFO - filelock -   Lock 140203072037776 released on cached/2768fc6cab7211630a47d239a3c467e01b5edcc650491f3777f181979ed61486.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/modeling_auto.py:825: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  FutureWarning,\n","10/23/2020 15:50:38 - INFO - filelock -   Lock 140201760401392 acquired on cached/dfce0c30714b109db92d119a65f60c177b0307b001aaeab3acb46baa6fd83caf.d62bc4460f435335df940faeff855fa04937181751e23f4db6ef38919d948abc.lock\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e4307ee8b1dc4da48c87eb89a7de9c2a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=862955157.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["10/23/2020 15:52:06 - INFO - filelock -   Lock 140201760401392 released on cached/dfce0c30714b109db92d119a65f60c177b0307b001aaeab3acb46baa6fd83caf.d62bc4460f435335df940faeff855fa04937181751e23f4db6ef38919d948abc.lock\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["10/23/2020 15:52:20 - INFO - __main__ -   Training/evaluation parameters <__main__.Args object at 0x7f83924700f0>\n","/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1374: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","10/23/2020 15:52:20 - INFO - __main__ -   Creating features from dataset file at cached\n","10/23/2020 15:52:34 - INFO - __main__ -   Saving features into cached file cached/gpt2_cached_lm_512\n","10/23/2020 15:52:34 - INFO - __main__ -   ***** Running training *****\n","10/23/2020 15:52:34 - INFO - __main__ -     Num examples = 26450\n","10/23/2020 15:52:34 - INFO - __main__ -     Num Epochs = 3\n","10/23/2020 15:52:34 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","10/23/2020 15:52:34 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","10/23/2020 15:52:34 - INFO - __main__ -     Gradient Accumulation steps = 1\n","10/23/2020 15:52:34 - INFO - __main__ -     Total optimization steps = 19836\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b58ea3b210d4a25ad662c6a5596433e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Epoch', max=3.0, style=ProgressStyle(description_width='i…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"784565a1ba054a87ac3f3fbfb4f8d61f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Iteration', max=6612.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-71-23c2cb26138e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinetune_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgenerator_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINETUNED_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFINETUNED_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-70-221d21e73bc5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(df_trn, df_val)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_cache_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" global_step = %s, average loss = %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-69-dc568a147fd6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, train_dataset, model, tokenizer)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# model outputs are always tuple in transformers (see doc)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         )\n\u001b[1;32m    780\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    651\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m                 )\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         )\n\u001b[1;32m    293\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# output_attn: a, present, (attentions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mpresent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mattn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_gpt2.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, q, k, v, attention_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# if only \"normal\" attention layer implements causal mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mns\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnd\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"hewj-2YcALXf"},"source":["### Main"]},{"cell_type":"markdown","metadata":{"id":"yEdRVlCrl_tL"},"source":["These are some helper function to combine every module of the pipeline."]},{"cell_type":"markdown","metadata":{"id":"rlS1T92oq_Du"},"source":["First, given a dialog context **x** = $\\{x_1,...,x_n\\}$, extract the seed entity **s** $\\in$ **x** and determine *k* candidate entities from the knowledge graph. "]},{"cell_type":"code","metadata":{"id":"942VPHunuK96","executionInfo":{"status":"ok","timestamp":1603468709209,"user_tz":-180,"elapsed":1093,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def seed_entity(dialog_context):\n","  seed = ''\n","\n","  for entity in all_entities:\n","    try:\n","      if (re.search(r'\\b{}\\b'.format(entity), dialog_context)) and len(seed) < len(entity):\n","        seed = entity\n","    except:\n","      continue\n","      \n","  return seed\n","\n","\n","def build_candidates(dialog_context, k=50):\n","  \"\"\"\n","  Randomly choose k entities from the 1-hop neighbourhood of the seed entity.\n","  \"\"\"\n","  seed = seed_entity(dialog_context)\n","\n","  if seed == '':\n","    print('Seed entity not found.')\n","    return None\n","  else:\n","    print('Seed entity: {}'.format(seed))\n","\n","  mask = triples_df['Subject'] == seed\n","  candidates = triples_df[mask][['Relation', 'Object']].drop_duplicates()\n","  candidates = candidates.sample(min(len(candidates), k))\n","\n","  candidates['Message'] = dialog_context + ' [SEP] ' + candidates['Relation'] + ' [SEP] ' + candidates['Object']\n","  candidates['Label'] = 1  # artificially impute it\n","  candidates = candidates[['Message', 'Label']]\n","\n","  return candidates"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5ynkH94IOxH"},"source":["Generate responses by inputing the object entity at the beginning of each sentence."]},{"cell_type":"code","metadata":{"id":"b2xRDljKLQMC","executionInfo":{"status":"ok","timestamp":1603468711891,"user_tz":-180,"elapsed":785,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["import random\n","\n","def generate_responses(tokenizer, model, conversations):\n","  user_input = conversations['Message'].tolist()\n","  start_entities = conversations['Object'].tolist()\n","\n","  responses = []\n","\n","  for step in range(len(conversations)):\n","      # encode the user input, add the eos_token, add the beginning entity of the generator and return a tensor in Pytorch\n","      user_turn = tokenizer.encode(user_input[step] + tokenizer.eos_token + start_entities[step], return_tensors='pt')\n","      \n","      # generated a response   \n","      response = model.generate(\n","      user_turn, max_length=1000,\n","      pad_token_id=tokenizer.eos_token_id\n","      )\n","\n","      decoded_response = tokenizer.decode(response[0], skip_special_tokens=True)\n","      full_response = start_entities[step] + decoded_response[-(len(decoded_response) - len(user_input[step]) - len(start_entities[step])):]\n","\n","      responses.append(full_response)\n","\n","  return responses"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJoIXuDHITEN"},"source":["Then re-rank these responses."]},{"cell_type":"code","metadata":{"id":"rm6Hodo5MnBZ","executionInfo":{"status":"ok","timestamp":1603470176528,"user_tz":-180,"elapsed":1476,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["def score(cxt, hyp, tokenizer, model):\n","  model_input = tokenizer.encode(cxt + \"<|endoftext|>\" + hyp, return_tensors=\"pt\")\n","  result = model(model_input, return_dict=True)\n","  return torch.sigmoid(result.logits)\n","  \n","def rank_responses(ranker_tokenizer, ranker_model, dialogue_context, responses):\n","  scores = []\n","\n","  for i, response in enumerate(responses):\n","    scores.append(score(dialogue_context, response, ranker_tokenizer, ranker_model).squeeze().item())\n","\n","  return sorted(zip(scores, responses), key=lambda x: x[0], reverse=True)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nEjY00PSm3g7"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"aAkonibUIWci"},"source":["\n","This is the main code block. Use this to interact with the system."]},{"cell_type":"code","metadata":{"id":"4Bc1V9lz4slF","executionInfo":{"status":"ok","timestamp":1603468805426,"user_tz":-180,"elapsed":90188,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"8b232d14-7586-491b-84a7-2125f3b3c872","colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["text = input(\"User: \")\n","top_k = 40  \n","\n","\n","def build_responses(dialog_context):\n","    candidates = build_candidates(dialog_context) \n","\n","    if candidates is None:\n","      print('Seed entity not found. Try another sentence.')\n","      return\n","\n","    cand_loader = create_data_loader(candidates, tokenizer, MAX_LEN, BATCH_SIZE) \n","    _, _, _, predicted_scores, predicted_labels = eval_model(classifier, cand_loader, loss_fn, device, len(data_test))\n","\n","    top_scores = sorted(zip(range(len(predicted_scores)), predicted_scores), key=lambda x: x[1], reverse=True)[:top_k]\n","\n","    candidates.reset_index(drop=True, inplace=True)\n","\n","    dialogpt_cand = []\n","    for i, pred in top_scores:\n","      m, _, o = candidates['Message'][i].split('[SEP]')\n","      dialogpt_cand.append({\n","          'Message': m,\n","          'Object': o,\n","          'Predictions': pred\n","      })\n","\n","    dialogpt_cand = pd.DataFrame(dialogpt_cand)\n","    responses = generate_responses(generator_tokenizer, generator_model, dialogpt_cand)\n","\n","    return rank_responses(ranker_tokenizer, ranker_model, text, responses), predicted_labels\n","\n","ranked_responses, _ = build_responses(text)\n","print(\"Bot: \", ranked_responses[0][1])"],"execution_count":75,"outputs":[{"output_type":"stream","text":["User: Do you like Iron Man?\n","Seed entity: Iron Man\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Bot:   House of M, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man, Iron Man\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bGLl-8OxIblW"},"source":["### Analysis"]},{"cell_type":"markdown","metadata":{"id":"z6D7UNlmIeVJ"},"source":["#### Quantitative metrics (entity-F1, recall@k)\n","\n","To compare our method to the baseline, we measure the entity-F1 score for entity prediction (KG-copy network) and recall@k (OpenDialKG) for k = 1, 3, 5, 10, 25.\n","\n","To make this experiment, we pick three seed entities who have between 40-50 neighbours in the Knowledge Graphs and for each of them, we build an artifical dialog context:<br>\n","*Kanye West* is a great songwriter. <br>\n","*Game of Thrones* is my favourite series. <br>\n","*Shrek Forever After* is such a fun movie. \n","\n","We manually annotate each dialogue context's candidate entities as being relevant and irrelevant and we compare these results to the results of the system. \n","\n","We run this experiment both on the base model and the fine-tuned one.\n","\n","Make sure you have the following files in your working directory:\n","- ```kanye_west.csv```\n","- ```got.csv```\n","- ```shrek.csv```"]},{"cell_type":"code","metadata":{"id":"lOu_tyaoImK1","executionInfo":{"status":"ok","timestamp":1603468990574,"user_tz":-180,"elapsed":155863,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"67444bd3-e616-4fa5-8c38-248d4e8e9dc1","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["eval_data = [('Kanye West is a great songwriter.', 'kanye_west.csv'),\n","             ('Game of Thrones is my favourite series.', 'got.csv'),\n","             ('Shrek Forever After is such a fun movie.', 'shrek.csv')\n","]\n","\n","r_1, r_3, r_5, r_10, r_25 = [], [], [], [], []\n","predictions = []\n","ground_truth = []\n","\n","for dialog_context, csv_file in eval_data:\n","  print(\"Running experiment for...\")\n","  print(dialog_context)\n","\n","  responses, predicted_labels = build_responses(dialog_context)\n","  predictions.append(predicted_labels)\n","  responses = [r[1] for r in responses]\n","\n","  test_df = pd.read_csv(csv_file)\n","  test_df = test_df[['Subject', 'Object', 'Label']]\n","  candidate_objects = list(test_df['Object'].unique())\n","  ground_truth.append(test_df['Label'].values.tolist())\n","\n","  total_relevant = test_df['Label'].sum()\n","  rel = 0\n","\n","  for k, response in enumerate(responses):\n","      seed = ''\n","      for obj in candidate_objects:\n","        try:\n","          if (re.search(r'\\b{}\\b'.format(obj), response)) and len(seed) < len(obj):\n","            seed = obj\n","        except:\n","          continue\n","      \n","      relevancy = test_df[(test_df['Object'] == seed) & (test_df['Label'] == 1)].drop_duplicates()['Label'].unique()\n","\n","      if len(relevancy) == 1:\n","        rel += 1\n","\n","      if k == 0:\n","         r_1.append(rel / total_relevant * 100)\n","      if k == 2:\n","         r_3.append(rel / total_relevant * 100)\n","      if k == 4:\n","         r_5.append(rel / total_relevant * 100)\n","      if k == 9:\n","         r_10.append(rel / total_relevant * 100)\n","      if k == 24:\n","         r_25.append(rel / total_relevant * 100)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Running experiment for...\n","Kanye West is a great songwriter.\n","Seed entity: Kanye West\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Running experiment for...\n","Game of Thrones is my favourite series.\n","Seed entity: Game of Thrones\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Running experiment for...\n","Shrek Forever After is such a fun movie.\n","Seed entity: Shrek Forever After\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2nDe16BpXlF8","executionInfo":{"status":"ok","timestamp":1603468996843,"user_tz":-180,"elapsed":2910,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"1d3b4d99-ca12-4969-ea39-c375dd32f04d","colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["print('Recall@1:', sum(r_1) / 3)\n","print('Recall@3:',  sum(r_3) / 3)\n","print('Recall@5:',sum(r_5) /3 )\n","print('Recall@10:',  sum(r_10) / 3)\n","print('Recall@25:',  sum(r_25) /3 )"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Recall@1: 5.619658119658119\n","Recall@3: 11.730769230769232\n","Recall@5: 17.072649572649574\n","Recall@10: 20.128205128205128\n","Recall@25: 60.85470085470086\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YsthVnVOcZIO","executionInfo":{"status":"ok","timestamp":1603469006587,"user_tz":-180,"elapsed":2339,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"ca118c48-ee0b-4074-b628-3b4d806a8189","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["true_pos, false_pos, false_neg = 0, 0, 0\n","\n","for i in range(len(predictions)):\n","  for j in range(len(predictions[i])):\n","    if predictions[i][j] == 1:\n","      if predictions[i][j] == ground_truth[i][j]:\n","        true_pos += 1\n","      else:\n","        false_pos += 1\n","    elif ground_truth[i][j] == 1:\n","      false_neg += 1\n","\n","print(\"Entity F1: \", 100 * true_pos / (true_pos + 1/2 * (false_pos + false_neg)))"],"execution_count":78,"outputs":[{"output_type":"stream","text":["Entity F1:  59.09090909090909\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dFb9pNLIImqa"},"source":["#### Qualitative analysis"]},{"cell_type":"markdown","metadata":{"id":"1ql4SW5IL5Xd"},"source":["```ranker_input_pruned.pkl``` contains a dataset with sentences extracted from OpenDialKg together with 5 candidate entities and their classifying scores. We will use this to perform some qualitative analysis. "]},{"cell_type":"code","metadata":{"id":"YLVAS2R_L25d","executionInfo":{"status":"ok","timestamp":1603470089671,"user_tz":-180,"elapsed":1126,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"ee3436ee-d0ca-46c1-96a0-b7cf4d11765d","colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["import pandas as pd\n","\n","# this will be the maximum number of answers generated by the finetuned generator\n","max_injected_answers = 5\n","\n","\n","conversations = pd.read_pickle('ranker_input_pruned.pkl')\n","\n","conversations = conversations.groupby(['Message', 'Object']).head(1)\n","conversations.sort_values(by=['Message', 'Predictions'], inplace=True, ascending=False)\n","conversations = conversations.groupby('Message').head(max_injected_answers).reset_index(drop=True)\n","\n","conversations.drop(['index', 'Subject', 'Relation', 'Label', 'level_0'], inplace=True, axis=1)\n","conversations"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Message</th>\n","      <th>Object</th>\n","      <th>Predictions</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>did you know Clay Aiken is friends with her?</td>\n","      <td>Tyra Banks</td>\n","      <td>0.999994</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>did you know Clay Aiken is friends with her?</td>\n","      <td>Artist</td>\n","      <td>0.999992</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>did you know Clay Aiken is friends with her?</td>\n","      <td>Pop music</td>\n","      <td>0.999991</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>did you know Clay Aiken is friends with her?</td>\n","      <td>Decca Records</td>\n","      <td>0.999991</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>did you know Clay Aiken is friends with her?</td>\n","      <td>RCA Records</td>\n","      <td>0.999991</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1185</th>\n","      <td>To Have and Have Not was also written by Erne...</td>\n","      <td>Warner Bros. Entertainment</td>\n","      <td>0.999992</td>\n","    </tr>\n","    <tr>\n","      <th>1186</th>\n","      <td>To Have and Have Not was also written by Erne...</td>\n","      <td>World War II</td>\n","      <td>0.999991</td>\n","    </tr>\n","    <tr>\n","      <th>1187</th>\n","      <td>To Have and Have Not was also written by Erne...</td>\n","      <td>Walter Brennan</td>\n","      <td>0.999991</td>\n","    </tr>\n","    <tr>\n","      <th>1188</th>\n","      <td>To Have and Have Not was also written by Erne...</td>\n","      <td>War film</td>\n","      <td>0.999990</td>\n","    </tr>\n","    <tr>\n","      <th>1189</th>\n","      <td>To Have and Have Not was also written by Erne...</td>\n","      <td>Romance Film</td>\n","      <td>0.999990</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1190 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                Message  ... Predictions\n","0          did you know Clay Aiken is friends with her?  ...    0.999994\n","1          did you know Clay Aiken is friends with her?  ...    0.999992\n","2          did you know Clay Aiken is friends with her?  ...    0.999991\n","3          did you know Clay Aiken is friends with her?  ...    0.999991\n","4          did you know Clay Aiken is friends with her?  ...    0.999991\n","...                                                 ...  ...         ...\n","1185   To Have and Have Not was also written by Erne...  ...    0.999992\n","1186   To Have and Have Not was also written by Erne...  ...    0.999991\n","1187   To Have and Have Not was also written by Erne...  ...    0.999991\n","1188   To Have and Have Not was also written by Erne...  ...    0.999990\n","1189   To Have and Have Not was also written by Erne...  ...    0.999990\n","\n","[1190 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"uOcfRDftKOCy"},"source":["We also need some sentences generated by KG-copy network for comparison."]},{"cell_type":"code","metadata":{"id":"CNL9LvZTKOJT","executionInfo":{"status":"ok","timestamp":1603470093287,"user_tz":-180,"elapsed":1249,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["kgcopy_sentences = {\n","    \"what is the name of the captain of mexico ?\" : \"<andres guardado>andres guardado.\",\n","    \"I like this team.\" : \"<nigeria>they are a good team.\",\n","    \"who is the captain of iceland?\" : \"<aron gunnarsson>aron gunnarsson is the captain.\",\n","    \"who is the captain of italy?\" : \"<giorgio chiellini>giorgio chiellini is the captain.\",\n","    \"who is the coach for italy?\" : \"<roberto mancini>roberto mancini is the coach\",\n","    \"who is the coach of bayern munich?\" : \"<niko kovac>niko kovac\",\n","    \"who is senegal ’s best current player not including mane ?\" : \"<keita balde diao>i think it is the best player in the world cup\",\n","    \"who ’s your favorite player ?\" : \"<messi>i think eden hazard is the best player\"\n","}"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s1m2Ghh_KSoz"},"source":["We create a dictionary with messages as keys and answers as values, and include *num_injected_ans* finetuned answers (with a maximum of 5).\n","The next cell computes sentences generated by GPT-2 and GPT-2 with entity injection."]},{"cell_type":"code","metadata":{"id":"kvwor7VxKS7U","executionInfo":{"status":"ok","timestamp":1603470141894,"user_tz":-180,"elapsed":47899,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"71ccf91e-3134-4d50-e4bb-35394bb1d4fa","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import random\n","\n","# this dictionary will have as keys messages and as values generated responses\n","# for each key, the first num_injected_ans values will be answers generated with entity injection\n","# and the last one will be generated with the GPT-2 model as-is\n","context_answer = dict()\n","num_injected_ans = 1\n","\n","user_input = conversations['Message'].tolist()\n","start_entities = conversations['Object'].tolist()\n","\n","# set the number of generated sentences, with a maximum of len(user_input) * (num_injected_ans + 1)\n","size_context_answer = len(user_input) * (num_injected_ans + 1)\n","\n","step = 0\n","k = 50\n","\n","while step < min(size_context_answer, k):\n","    # encode the user input, add the eos_token, add the beginning entity of the generator and return a tensor in Pytorch\n","    user_turn = generator_tokenizer.encode(user_input[step] + generator_tokenizer.eos_token + start_entities[step], return_tensors='pt')\n","    \n","    \n","    \n","    # generated a response   \n","    response = generator_model.generate(\n","    user_turn, max_length=1000,\n","    pad_token_id = generator_tokenizer.eos_token_id\n","    )\n","\n","    decoded_response = generator_tokenizer.decode(response[0], skip_special_tokens=True)\n","    full_response = start_entities[step] + decoded_response[-(len(decoded_response) - len(user_input[step]) - len(start_entities[step])):]\n","\n","    if user_input[step] not in context_answer:\n","      print('\\nEntity injection: ')\n","      print('User: ' + user_input[step])\n","      context_answer[user_input[step]] = [full_response]\n","      print('Bot: ' + full_response + '\\n') \n","      \n","    else:\n","      if len(context_answer[user_input[step]]) < num_injected_ans:\n","        context_answer[user_input[step]] += [full_response]\n","        print('\\nEntity injection: ')\n","        print('User: ' + user_input[step])\n","        print('Bot: ' + full_response + '\\n') \n","        \n","      if len(context_answer[user_input[step]]) == num_injected_ans:\n","        # add the response of the as-is GPT-2 model at the end of the response list of each message\n","        user_turn_pt = generator_tokenizer.encode(user_input[step] + generator_tokenizer.eos_token, return_tensors='pt')\n","        print('\\nNo entity injection:')\n","        print('Pt User: ' + user_input[step])\n","    \n","    \n","        # generated a response\n","        pt_response = generator_model.generate(\n","        user_turn_pt, max_length=1000,\n","        pad_token_id = generator_tokenizer.eos_token_id\n","        )\n","\n","        decoded_response_pt = generator_tokenizer.decode(pt_response[0], skip_special_tokens=True)\n","        full_response_pt = decoded_response_pt[-(len(decoded_response_pt) - len(user_input[step])):]\n","        print('Pt Bot: ' + full_response_pt + '\\n\\n')\n","    \n","        context_answer[user_input[step]] += [full_response_pt]\n","        \n","        step += max_injected_answers - num_injected_ans -1\n","\n","    \n","    step += 1"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","Entity injection: \n","User: did you know Clay Aiken is friends with her?\n","Bot: Tyra Banks also starred in the movie. \n","\n","\n","No entity injection:\n","Pt User: did you know Clay Aiken is friends with her?\n","Pt Bot: I think they are dating. \n","\n","\n","\n","Entity injection: \n","User: Yes, it was published in 1958 like the other I mentioned before.\n","Bot: Breakfast at Tiffany's is a great read. \n","\n","\n","No entity injection:\n","Pt User: Yes, it was published in 1958 like the other I mentioned before.\n","Pt Bot: I think it was released in English. \n","\n","\n","\n","Entity injection: \n","User: Yes, for one thing, it starred Robert Downey Jr. and was written by the famous, late Stan Lee.\n","Bot: Wolverine and the X-Men are also great examples of this genre. \n","\n","\n","No entity injection:\n","Pt User: Yes, for one thing, it starred Robert Downey Jr. and was written by the famous, late Stan Lee.\n","Pt Bot: I like Stan Lee movies. \n","\n","\n","\n","Entity injection: \n","User: Yes, What Lies Beneath, When a Stranger Calls, and Vanilla Sky are all thrillers\n","Bot: Brian Geraghty wrote. \n","\n","\n","No entity injection:\n","Pt User: Yes, What Lies Beneath, When a Stranger Calls, and Vanilla Sky are all thrillers\n","Pt Bot: I can recommend. \n","\n","\n","\n","Entity injection: \n","User: Yes, Thorpe played many sports, including Baseball and Basketball.\n","Bot: Lute Olson also played Basketball. \n","\n","\n","No entity injection:\n","Pt User: Yes, Thorpe played many sports, including Baseball and Basketball.\n","Pt Bot: I know he is a golfer. \n","\n","\n","\n","Entity injection: \n","User: Yes, I love Stephen King movies.\n","Bot: The Wind Through the Keyhole is one of my favorites. Have you seen it? \n","\n","\n","No entity injection:\n","Pt User: Yes, I love Stephen King movies.\n","Pt Bot: I especially like the horror movies. Do you like him? \n","\n","\n","\n","Entity injection: \n","User: Yes they are interesting Paper Towns is also Young-adult fiction.\n","Bot: Dragonsinger is a young adult fiction. \n","\n","\n","No entity injection:\n","Pt User: Yes they are interesting Paper Towns is also Young-adult fiction.\n","Pt Bot: I like that genre. \n","\n","\n","\n","Entity injection: \n","User: Yes that is, Monmouth Beach, New Jersey.\n","Bot: Jake Cherry starred in it. \n","\n","\n","No entity injection:\n","Pt User: Yes that is, Monmouth Beach, New Jersey.\n","Pt Bot: I love that movie! \n","\n","\n","\n","Entity injection: \n","User: Yes he did, The Wedding Date and Maid in Manhattan.\n","Bot: Jack Davenport starred in both of those movies. \n","\n","\n","No entity injection:\n","Pt User: Yes he did, The Wedding Date and Maid in Manhattan.\n","Pt Bot: I love him. \n","\n","\n","\n","Entity injection: \n","User: Yes actually The Lorax has been turned into an animation film.\n","Bot: Fiction or not, it is a great movie. \n","\n","\n","No entity injection:\n","Pt User: Yes actually The Lorax has been turned into an animation film.\n","Pt Bot: I think it was released in 1999. \n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4JJI2TZRKbQT"},"source":["The next cell creates sentences generated by GPT2 for messages from the KGCopy dataset."]},{"cell_type":"code","metadata":{"id":"yjWxV_4rKb0k","executionInfo":{"status":"ok","timestamp":1603470159077,"user_tz":-180,"elapsed":6995,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"e8428c47-b2e8-444e-ef25-12fb40fd6326","colab":{"base_uri":"https://localhost:8080/","height":810}},"source":["import re\n","\n","context_answer_kg = dict()\n","\n","start_entities = conversations['Object'].tolist()    \n","    \n","    \n","for sentence in kgcopy_sentences.keys():   \n","    \n","    start_entity = re.search('<(.*)>', kgcopy_sentences[sentence]).group(1)\n","    kganswer = kgcopy_sentences[sentence].split('>')[1]\n","\n","    # encode the user input, add the eos_token, add the beginning entity of the generator and return a tensor in Pytorch\n","    user_turn = generator_tokenizer.encode(sentence + generator_tokenizer.eos_token + start_entity, return_tensors='pt')\n","    print('Context: ' + sentence)\n","    \n","    \n","    # generated a response   \n","    response = generator_model.generate(\n","    user_turn, max_length=1000,\n","    pad_token_id = generator_tokenizer.eos_token_id\n","    )\n","\n","    decoded_response = generator_tokenizer.decode(response[0], skip_special_tokens=True)\n","    full_response = start_entity + decoded_response[-(len(decoded_response) - len(sentence) - len(start_entity)):]\n","\n","    context_answer_kg[sentence] = [full_response]\n","    context_answer_kg[sentence] += [kganswer]\n","    \n","    print('Bot: ' + full_response) \n","    print('KGBot: ' + kganswer + '\\n')\n","        \n","\n","context_answer_kg"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Context: what is the name of the captain of mexico ?\n","Bot: andres guardado \n","KGBot: andres guardado.\n","\n","Context: I like this team.\n","Bot: nigeria is a good team. \n","KGBot: they are a good team.\n","\n","Context: who is the captain of iceland?\n","Bot: aron gunnarsson? \n","KGBot: aron gunnarsson is the captain.\n","\n","Context: who is the captain of italy?\n","Bot: giorgio chiellini? \n","KGBot: giorgio chiellini is the captain.\n","\n","Context: who is the coach for italy?\n","Bot: roberto mancini? \n","KGBot: roberto mancini is the coach\n","\n","Context: who is the coach of bayern munich?\n","Bot: niko kovacic \n","KGBot: niko kovac\n","\n","Context: who is senegal ’s best current player not including mane ?\n","Bot: keita balde diaowho is senegal ’s best current player not including mane?keita balde diao \n","KGBot: i think it is the best player in the world cup\n","\n","Context: who ’s your favorite player ?\n","Bot: messi \n","KGBot: i think eden hazard is the best player\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'I like this team.': ['nigeria is a good team. ', 'they are a good team.'],\n"," 'what is the name of the captain of mexico ?': ['andres guardado ',\n","  'andres guardado.'],\n"," 'who is senegal ’s best current player not including mane ?': ['keita balde diaowho is senegal ’s best current player not including mane?keita balde diao ',\n","  'i think it is the best player in the world cup'],\n"," 'who is the captain of iceland?': ['aron gunnarsson? ',\n","  'aron gunnarsson is the captain.'],\n"," 'who is the captain of italy?': ['giorgio chiellini? ',\n","  'giorgio chiellini is the captain.'],\n"," 'who is the coach for italy?': ['roberto mancini? ',\n","  'roberto mancini is the coach'],\n"," 'who is the coach of bayern munich?': ['niko kovacic ', 'niko kovac'],\n"," 'who ’s your favorite player ?': ['messi ',\n","  'i think eden hazard is the best player']}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"XIFNqhkHKkst"},"source":["Once the answers are generated, rank them using DialogRPT. *model_card* can be set to either rank by *depth*, *width* or *updown*"]},{"cell_type":"code","metadata":{"id":"bfM6e09MKlAy","executionInfo":{"status":"ok","timestamp":1603469557904,"user_tz":-180,"elapsed":56949,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}}},"source":["model_card = \"microsoft/DialogRPT-depth\"   \n","ranker_tokenizer = AutoTokenizer.from_pretrained(model_card)\n","ranker_model = AutoModelForSequenceClassification.from_pretrained(model_card)"],"execution_count":87,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A50YYIb7Ksr0"},"source":["The next cell ranks the answers for each unique message. <br>\n","Set *con_ans* to *context_answer* if comparison between GTP2 as-is and GPT-2 with entity injection in the answer, and to *context_answer_kg* if comparison between KG-Copy answers and GPT-2 with entity injection."]},{"cell_type":"code","metadata":{"id":"pNyu8ceiKtAl","executionInfo":{"status":"ok","timestamp":1603470187557,"user_tz":-180,"elapsed":7703,"user":{"displayName":"Maria Diea","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjG0pvlBImvwoiVUxSbUmWX8UdoN_DU2KcdUnh-oQ=s64","userId":"05403296270855029573"}},"outputId":"c4ba15c6-9646-473f-96a7-b4e47e0cc4ac","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["entity_gen_times = 0\n","simple_gen_times = 0\n","\n","# con_ans takes context_answer_kg if ranking of KGCopy vs GPT+entity\n","# or context_answer if ranking betweenGPT vs GPT+entity\n","con_ans = context_answer_kg\n","\n","\n","for message in con_ans.keys():\n","\n","\n","  print('\\n\\nContext: ' + message)\n","  \n","  max_score = 0\n","  entity_score_sum = 0\n","\n","  for i, response in enumerate(con_ans[message]):\n","      \n","      s = score(message, response, ranker_tokenizer, ranker_model).squeeze().item()\n","      \n","      \n","      if i == len(con_ans[message]) - 1:\n","          \n","          # we are over the answer generated by GPT2\n","          print(\"No entity answer: \")\n","\n","          if len(con_ans[message]) == 2:\n","            average_entity_answers = entity_score_sum\n","          else:\n","            average_entity_answers = entity_score_sum / (len(con_ans[message]) - 2) \n","          \n","          # compare the average score from the entity injection answers to the GPT2 answer scores\n","          if average_entity_answers < s:\n","              simple_gen_times += 1\n","          else:\n","              entity_gen_times += 1\n","          \n","          \n","      else:\n","          # we are in the answers with injected entities\n","          print('GPT + Entity answer: ')\n","          entity_score_sum += s\n","\n","      print(str(s) + ' ' + response)\n","\n","\n","print('\\n\\nTimes GPT2 + entity injection scored higher: ' + str((100 * entity_gen_times)/(entity_gen_times + simple_gen_times)) + '%')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["\n","\n","Context: what is the name of the captain of mexico ?\n","GPT + Entity answer: \n","0.15634453296661377 andres guardado \n","No entity answer: \n","0.15634453296661377 andres guardado.\n","\n","\n","Context: I like this team.\n","GPT + Entity answer: \n","0.35517174005508423 nigeria is a good team. \n","No entity answer: \n","0.07859209179878235 they are a good team.\n","\n","\n","Context: who is the captain of iceland?\n","GPT + Entity answer: \n","0.27688881754875183 aron gunnarsson? \n","No entity answer: \n","0.25066301226615906 aron gunnarsson is the captain.\n","\n","\n","Context: who is the captain of italy?\n","GPT + Entity answer: \n","0.37385594844818115 giorgio chiellini? \n","No entity answer: \n","0.430548757314682 giorgio chiellini is the captain.\n","\n","\n","Context: who is the coach for italy?\n","GPT + Entity answer: \n","0.3264838457107544 roberto mancini? \n","No entity answer: \n","0.33196067810058594 roberto mancini is the coach\n","\n","\n","Context: who is the coach of bayern munich?\n","GPT + Entity answer: \n","0.17353299260139465 niko kovacic \n","No entity answer: \n","0.18639254570007324 niko kovac\n","\n","\n","Context: who is senegal ’s best current player not including mane ?\n","GPT + Entity answer: \n","0.46220868825912476 keita balde diaowho is senegal ’s best current player not including mane?keita balde diao \n","No entity answer: \n","0.40302565693855286 i think it is the best player in the world cup\n","\n","\n","Context: who ’s your favorite player ?\n","GPT + Entity answer: \n","0.46328434348106384 messi \n","No entity answer: \n","0.26768621802330017 i think eden hazard is the best player\n","\n","\n","Times GPT2 + entity injection scored higher: 62.5%\n"],"name":"stdout"}]}]}